---
title: "**CNNs - Malaria image recogenization problem** \n \n Universitat Politècnica de Catalunya"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
author: '`r params$author`'
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    theme: united
    df_print: paged
    toc: yes
    toc_float: yes
params:
  show_code: TRUE
  seed: 1234
  author: 'Andreu Meca, Geraldo Gariza and Jan Leyva'
  #partition: 0.6666666666666666666667
  myDescription: 'Malaria is a deadly, infectious mosquito-borne disease caused by Plasmodium parasites. These parasites are transmitted by the bites of infected female Anopheles mosquitoes. With regular manual diagnosis of blood smears, it is an intensive manual process requiring proper expertise in classifying and counting the parasitized and uninfected cells. Typically this may not scale well and might cause problems if we do not have the right expertise in specific regions around the world. We are lucky to have researchers at the Lister Hill National Center for Biomedical Communications (LHNCBC), part of National Library of Medicine (NLM) who have carefully collected and annotated this dataset of healthy and infected blood smear images. There is a balanced dataset of 13779 malaria and non-malaria (uninfected) cell images. The dataset consist of near thousand images downloaded from the official website that have been resized (64x64x3). The images are organized in three folders: train, validation and test. Deep Learning models, or to be more specific, Convolutional Neural Networks (CNNs) have proven to be really effective in a wide variety of computer vision tasks.'
  #dataset: 
bibliography: scholar.bib  
---


\newpage

```{r setup_rmd, include=FALSE,echo=FALSE}
knitr::opts_chunk$set(echo = params$show_code)
knitr::opts_chunk$set(error = TRUE)
```


```{r packages, include=FALSE}
# If the package is not installed then it will be installed
if(!require("knitr")) install.packages("knitr")
if(!require("keras")) install.packages("keras")
if(!require("kerasR")) install.packages("kerasR")
if(!require("tfruns")) install.packages("tfruns")
if(!require("caret")) install.packages("caret")
if(!require("e1071")) install.packages("e1071")


library("knitr")
library("keras")
library("kerasR")
library("tfruns")
library("caret")
library("e1071")
```

# ```{r}
# reticulate::py_install("pillow")
# ```


```{r import data, include=FALSE}
base_dir<-"~/KOLMOGOROV/Assignment_CNN/malaria/malaria"
# train directories
train_dir<-file.path(base_dir,"train",fsep ="/")
train_dir_infected<-file.path(train_dir,"infected",fsep = "/")
train_dir_uninfected<-file.path(train_dir,"uninfected",fsep = "/")

# vaidation directories
validation_dir<-file.path(base_dir,"validation",fsep ="/")
validation_dir_infected<-file.path(validation_dir,"infected",fsep = "/")
validation_dir_uninfected<-file.path(validation_dir,"uninfected",fsep = "/")

# test directories
test_dir<-file.path(base_dir,"test",fsep ="/")
test_dir_infected<-file.path(test_dir,"infected",fsep = "/")
test_dir_uninfected<-file.path(test_dir,"uninfected",fsep = "/")
```


# Description data


`r params$myDescription`. 


# Preprocess

Once we have charged the directories of the `train`, `test` and `validation` we must to resize into a generator object.

```{r data importation}
# image_data_generator Generate batches of image data with real-time data augmentation. The data will be looped over (in batches).
train_datagen <- image_data_generator(rescale = 1/255) #
validation_datagen <- image_data_generator(rescale = 1/255) #
#flow_images_from_directory Generates batches of data from images in a directory (with optional augmented/normalized data)
train_generator <- flow_images_from_directory(
train_dir,
train_datagen,
target_size = c(64, 64),
batch_size = 10,
class_mode = "binary"
)
validation_generator <- flow_images_from_directory(
validation_dir,
validation_datagen,
target_size = c(64, 64),
batch_size = 10,
class_mode = "binary"
)
batch <- generator_next(train_generator)
str(batch) 
```

```{r}
img<-image_dataset_from_directory(test_dir,labels='inferred')

```


```{r}
test_datagen <- image_data_generator(rescale = 1/255) #

test_generator <- flow_images_from_directory(
test_dir,
test_datagen,
target_size = c(64, 64),
batch_size = 1,
class_mode = "binary"
)
```


# CNN definition

```{r cnn def}
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu",
  input_shape = c(64, 64, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_flatten() %>%
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")
```

 
```{r cnn summary}
summary(model)
```

## Define the parametres
```{r}
model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = c("accuracy")
)
```

We use a loss function `binary crossentropy` because the aim of this CNN is predict two categories (malaria or not malaria).
The metric used is the `accuracy.`

```{r}
history <- model %>% fit_generator(
  train_generator,
  steps_per_epoch = 100,
  epochs = 10, 
  validation_data = validation_generator,
  validation_steps = 50
)
```
In order to see the model performance we plot the performance for each epoch of the CNN.
```{r history performance}
plot(history)
```


```{no usar}
  # history <- model %>% fit(
  #   train_generator,
  #   steps_per_epoch = 64, #100
  #   epochs = 20, # 20
  #   validation_data = validation_generator,
  #   validation_steps = 50 #50
)
```

In order to save the model
```{r save_model_hdf5}
model %>% save_model_hdf5("cnn.h5")
```

In order to load the model
```{r load_model_hdf5}
# model_load <- load_model_hdf5("cnn.h5")
```


## Tunning hyperparameter
In this section we going to tune the hyperparameter `batch_size` exploring the
grid c.16; 32; 64.

First of all, we set hyperparameter flags.
```{r flags}
FLAGS <- flags(
  flag_string("hl1", "batch size"))
```

Re-define the model introducing the flags in order to tune the hyperparameter.
```{r Tunning hyperparameter}
model %>% fit(train_generator, train_generator$labels, epochs = 10, 
              batch_size = FLAGS$hl1)
```

Training the model that is stored in `cnn_assignment.R` with the different `batch size` in a loop.
```{r}
for (hl1 in c(16, 32, 64)){
training_run("cnn_assignment.R", flags = c(hl1 = hl1))
}  
```

If we want see the performance of the runs that we did before:
```{r view runs}
View(ls_runs())
```

In order to compare the last two models:
```{r compare}
compare_runs()
```

### `callbacks()` Implemention

In this section is implemented a an early-stopping `callbacks()` that stop the training validation accuracy stops improving for more than two epochs. For this we used `EarlyStopping` as a function inside `callbacks`. We specify `patience` = 3 to stop the training when the `accuracy` stop improving for *more than two epochs*.

```{r callback}
model %>% fit(train_generator, 
              epochs = 50,
              callbacks = list(callback_model_checkpoint("cnn.h5"),
                               EarlyStopping(monitor = "accuracy", 
                                             patience = 3)))
```


## Performance of the CNN 

### Evaluate
```{r evaluate}
# evaluate
scores <- model %>% evaluate(test_generator, 
                             test_generator$labels, 
                             verbose = 0)

# Output metrics
cat('Test loss:', scores[[1]], '\n')
cat('Test accuracy:', scores[[2]], '\n')
```



### Prediction
For predict we going to use `predict()` function that returns a probability of been group 0 or 1, then we will force it to 0 or 1 in order to then do the confusion matrix.
```{r prediction}
y_pred <-model %>% 
            predict(test_generator)

y_pred_ <- c()
for(i in 1:length(y_pred)){
  ifelse(y_pred[i] > 0.50001, y_pred_[i] <- 1, y_pred_[i] <- 0)
}
```

### Confusion Matrix

Keras don't include a Confusion Matrix, for this reason we going to use `caret` package and his `confusionMatrix` function. First of all, we pass the prob bigger than 0.5 to class 1 else to 0. We did this because the image object is a generator and the function `predict_classes` do not accept generators, only vectors list or atomics. 
```{r confusion Matrix}
confusionMatrix(as.factor(test_generator$labels), as.factor(y_pred_))
```

The result show us the expected, the model overfitting the train data set, as we can see on the first *history* plot, as the train improve his performance linealy the validation set mantain constant and even go down the accuracy. This is a sign of overfitting. 

For futures works, will be interesting apply different techniques for mitigate the overfitting such as dropour and weight decay (L2 regularization) or use data augmentation.


# Convolutional AutoEncoder (CAE)

6. Implement two Convolutional AutoEncoder (CAE). The first with 3 nodes
in z layer (or bottleneck), the second with 10 nodes in z layer. Feel free to
choose the number of convolutional layers, filter sizes, number of filters, 


## 1st Convolutional AutoEncoder

In this section we going to implement a CAE with 3 nodes in z layer.
- Convolutional layers
- Filter sizes
- Number of filters

*Convolutional Encoder*
```{r Convolutional Encoder}
model_enc <- keras_model_sequential() 
model_enc %>%
  layer_conv_2d(filters = 2, kernel_size = c(3,3), 
                activation = "relu", padding = "same",
                input_shape = c(64, 64, 3))  %>%
  layer_max_pooling_2d(pool_size = c(2,2), padding = "same")  %>%
  layer_conv_2d(filters = 1, kernel_size = c(3,3), 
                activation = "relu", padding = "same") %>%
  layer_max_pooling_2d(pool_size = c(2,2), padding = "same")  %>%
  layer_conv_2d(filters = 2, kernel_size = c(3,3), 
                activation = "relu", padding = "same") %>%
  layer_max_pooling_2d(pool_size = c(2,2), padding = "same") %>%
    layer_conv_2d(filters = 8, kernel_size = c(3,3), 
                activation = "relu", padding = "same") %>%
  layer_max_pooling_2d(pool_size = c(2,2), padding = "same") 
summary(model_enc)
```


*Convolutional Decoder*
```{r Convolutional Decoder}
model_dec <- keras_model_sequential() 
model_dec %>%
  layer_conv_2d(filters = 4, kernel_size = c(3,3), 
                activation = "relu", padding = "same",
                input_shape = c(3, 3, 8))  %>%
  layer_upsampling_2d(size = c(2,2))  %>%
  layer_conv_2d(filters = 8, kernel_size = c(3,3), 
                activation = "relu", padding = "same")  %>%
  layer_upsampling_2d(size = c(2,2))  %>%
  # Important: no padding 
  layer_conv_2d(filters = 1, kernel_size = c(3,3), 
                activation = "relu")  %>%
  layer_upsampling_2d(size = c(2,2))  
summary(model_dec)
```


*Autoencoder* 
```{r}
CAE<-keras_model_sequential()
CAE %>%model_enc%>%model_dec

summary(CAE)
```





```{r test enc}
model_enc <- keras_model_sequential() 
model_enc %>%
  layer_conv_2d(filters = 3, kernel_size = c(3,3), 
                activation = "relu", padding = "same",
                input_shape = c(64, 64, 3))  %>%
  layer_max_pooling_2d(pool_size = c(4,4), padding = "same")  %>%
  layer_conv_2d(filters = 10, kernel_size = c(4,4), 
                activation = "relu", padding = "same") %>%
  layer_max_pooling_2d(pool_size = c(2,2), padding = "same")  %>%
  layer_conv_2d(filters = 20, kernel_size = c(4,4), 
                activation = "relu", padding = "same") %>%
  layer_max_pooling_2d(pool_size = c(2,2), padding = "same") %>%
    layer_conv_2d(filters = 40, kernel_size = c(8,8), 
                activation = "relu", padding = "same") %>%
  layer_max_pooling_2d(pool_size = c(2,2), padding = "same") 
summary(model_enc)
```



```{r test dec}
model_dec <- keras_model_sequential() 
model_dec %>%
  layer_conv_2d(filters = 40, kernel_size = c(3,3), 
                activation = "relu", padding = "same",
                input_shape = c(2, 2, 40))  %>%
  layer_upsampling_2d(size = c(2,2)) %>%
  layer_conv_2d(filters = 20, kernel_size = c(3,3), 
                activation = "relu", padding = "same") %>%
  layer_upsampling_2d(size = c(2,2)) %>%
  layer_conv_2d(filters = 10, kernel_size = c(3,3), 
                activation = "relu", padding = "same") %>%
  layer_upsampling_2d(size = c(2,2)) %>%
  layer_conv_2d(filters = 3, kernel_size = c(3,3), 
                activation = "relu", padding = "same") %>%
  layer_upsampling_2d(size = c(2,2)) %>%
  layer_conv_2d(filters = 3, kernel_size = c(3,3), 
                activation = "relu", padding = "same") %>%
    layer_upsampling_2d(size = c(2,2)) %>%
  layer_conv_2d(filters = 3, kernel_size = c(3,3), 
                activation = "relu", padding = "same")
summary(model_dec)

```

```{r test_2 dec}
model_dec <- keras_model_sequential() 
model_dec %>%
  layer_conv_2d(filters = 8, kernel_size = c(3,3), 
                activation = "relu", padding = "same",
                input_shape = c(4, 4, 8))  %>%
  layer_upsampling_2d(size = c(2,2)) %>%
  layer_conv_2d(filters = 16, kernel_size = c(3,3), 
                activation = "relu", padding = "same") %>%
  layer_upsampling_2d(size = c(2,2)) %>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3), 
                activation = "relu", padding = "same") %>%
  layer_upsampling_2d(size = c(2,2)) %>%
    layer_conv_2d(filters = 3, kernel_size = c(3,3), 
                activation = "relu", padding = "same") %>%
  layer_upsampling_2d(size = c(2,2)) %>%
summary(model_dec)

```


```{r}
CAE<-keras_model_sequential()
CAE %>%model_enc%>%model_dec
```



```{r}
CAE %>% compile(
  loss = "mean_squared_error",
  #optimizer = optimizer_rmsprop(),
  optimizer = "adam",
  metrics = c("mean_squared_error")
)
summary(CAE)
```


```{r}
history_CAE <- CAE %>% fit(
  x= train_generator, y = train_generator,   # Autoencoder
  epochs = 10, batch_size = 64 #alidation_data = list(x_test_cifra,x_test_cifra)
)
```


## AutoEncoder Prediction

```{r}
output_cifra<-predict(CAE,train_generator)
dim(output_cifra)
```

### From encoder to decoder
```{r}
enc_output_cifra<-predict(model_enc,train_generator)
dim(enc_output_cifra)
```
### From encoder to decoder

```{r}
dec_output_cifra<-predict(model_dec,enc_output_cifra)
dim(dec_output_cifra)
```


### Show image

```{r}
image_to_array(output_cifra, data_format = c("channels_last", "channels_first"))
```


```{r}
idx<-1
#x_test_cifra[idx,,,1]
im<-matrix(as.numeric(train_generator[[idx]])/255, nrow=64, ncol=64) 
image(1:64, 1:64, im)
```

```{r}
matrix(train_generator[2], 64, 64)
```


## 2nd Convolutional AutoEncoder

In this section we going to implement a CAE with 10 nodes in z layer.
- Convolutional layers
- Filter sizes
- Number of filters



7. Represent graphically the results from images test to show the association
between z layer activations and the class images. Compare the representations
displayed by both CAE architectures.




## new CAE ---------------------------
```{r}
img<-image_dataset_from_directory(train_generator,labels='inferred')

```



```{r model_enc 2}
model_enc <- keras_model_sequential() 
model_enc %>%
  layer_conv_2d(filters = 16, kernel_size = c(3,3), 
                activation = "relu", padding = "same",
                input_shape = c(28,28,1))  %>%
  layer_max_pooling_2d(pool_size = c(2,2), padding = "same")  %>%
  layer_conv_2d(filters = 8, kernel_size = c(3,3), 
                activation = "relu", padding = "same") %>%
  layer_max_pooling_2d(pool_size = c(2,2), padding = "same")  %>%
  layer_conv_2d(filters = 8, kernel_size = c(3,3), 
                activation = "relu", padding = "same") %>%
  layer_max_pooling_2d(pool_size = c(2,2), padding = "same") 
summary(model_enc)
```

```{r model_dec}
model_dec <- keras_model_sequential() 
model_dec %>%
  layer_conv_2d(filters = 8, kernel_size = c(3,3), 
                activation = "relu", padding = "same",
                input_shape = c(4, 4, 8))  %>%
  layer_upsampling_2d(size = c(2,2))  %>%
  layer_conv_2d(filters = 8, kernel_size = c(3,3), 
                activation = "relu", padding = "same")  %>%
  layer_upsampling_2d(size = c(2,2))  %>%
  # Important: no padding 
  layer_conv_2d(filters = 1, kernel_size = c(3,3), 
                activation = "relu")  %>%
  layer_upsampling_2d(size = c(2,2))  
summary(model_dec)
```

```{r model_Auto}
model_Auto<-keras_model_sequential()
model_Auto %>%model_enc%>%model_dec

summary(model_Auto)
```

```{r}
model_Auto %>% compile(
  loss = "mean_squared_error",
  #optimizer = optimizer_rmsprop(),
  optimizer = "adam",
  metrics = c("mean_squared_error")
)

```


```{r}
history <- model_Auto %>% fit(
  x= train_generator, y = train_generator,   # Autoencoder
  epochs = 5
  #  validation_data = list(x_test_cifra,x_test_cifra)
)
```





