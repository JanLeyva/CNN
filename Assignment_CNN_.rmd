---
title: "**CNNs - Malaria image recogenization problem** \n \n Universitat Politècnica de Catalunya"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
author: '`r params$author`'
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    theme: united
    df_print: paged
    toc: yes
    toc_float: yes
params:
  show_code: TRUE
  seed: 1234
  author: 'Andreu Meca, Geraldo Gariza and Jan Leyva'
  #partition: 0.6666666666666666666667
  myDescription: 'Malaria is a deadly, infectious mosquito-borne disease caused by Plasmodium parasites. These parasites are transmitted by the bites of infected female Anopheles mosquitoes. With regular manual diagnosis of blood smears, it is an intensive manual process requiring proper expertise in classifying and counting the parasitized and uninfected cells. Typically this may not scale well and might cause problems if we do not have the right expertise in specific regions around the world. We are lucky to have researchers at the Lister Hill National Center for Biomedical Communications (LHNCBC), part of National Library of Medicine (NLM) who have carefully collected and annotated this dataset of healthy and infected blood smear images. There is a balanced dataset of 13779 malaria and non-malaria (uninfected) cell images. The dataset consist of near thousand images downloaded from the official website that have been resized (64x64x3). The images are organized in three folders: train, validation and test. Deep Learning models, or to be more specific, Convolutional Neural Networks (CNNs) have proven to be really effective in a wide variety of computer vision tasks.'
  #dataset: 
bibliography: scholar.bib  
---


\newpage

```{r setup_rmd, include=FALSE,echo=FALSE}
knitr::opts_chunk$set(echo = params$show_code)
knitr::opts_chunk$set(error = TRUE)
```


```{r packages, include=FALSE}
# If the package is not installed then it will be installed
if(!require("knitr")) install.packages("knitr")
if(!require("keras")) install.packages("keras")
if(!require("kerasR")) install.packages("kerasR")
if(!require("tfruns")) install.packages("tfruns")

library("knitr")
library("keras")
library(kerasR)
library(tfruns)
```

```{r}
reticulate::py_install("pillow")
```


```{r import data, include=FALSE}
base_dir<-"~/KOLMOGOROV/Assignment_CNN/malaria/malaria"
# train directories
train_dir<-file.path(base_dir,"train",fsep ="/")
train_dir_infected<-file.path(train_dir,"infected",fsep = "/")
train_dir_uninfected<-file.path(train_dir,"uninfected",fsep = "/")

# vaidation directories
validation_dir<-file.path(base_dir,"validation",fsep ="/")
validation_dir_infected<-file.path(validation_dir,"infected",fsep = "/")
validation_dir_uninfected<-file.path(validation_dir,"uninfected",fsep = "/")

# test directories
test_dir<-file.path(base_dir,"test",fsep ="/")
test_dir_infected<-file.path(test_dir,"infected",fsep = "/")
test_dir_uninfected<-file.path(test_dir,"uninfected",fsep = "/")
```


# Description data


`r params$myDescription`. 


# Preprocess

Once we have charged the directories of the `train`, `test` and `validation` we must to rez

```{r data importation}
# image_data_generator Generate batches of image data with real-time data augmentation. The data will be looped over (in batches).
train_datagen <- image_data_generator(rescale = 1/255) #
validation_datagen <- image_data_generator(rescale = 1/255) #
#flow_images_from_directory Generates batches of data from images in a directory (with optional augmented/normalized data)
train_generator <- flow_images_from_directory(
train_dir,
train_datagen,
target_size = c(64, 64),
batch_size = 20,
class_mode = "binary"
)
validation_generator <- flow_images_from_directory(
validation_dir,
validation_datagen,
target_size = c(64, 64),
batch_size = 20,
class_mode = "binary"
)
batch <- generator_next(train_generator)
str(batch) 
```

# CNN definition

```{r cnn def}
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu",
  input_shape = c(64, 64, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_flatten() %>%
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")
```

 
```{r}
summary(model)
```

## Define the parametres
```{r}
model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = c("accuracy")
)
```

We use a loss function `binary crossentropy` because the aim of this CNN is predict two categories (malaria or not malaria).
The metric used is the `accuracy.`

```{r}
history <- model %>% fit(
  train_generator,
  epochs = 10, # 10
  validation_data = validation_generator,
)
```
In order to see the model performance we plot the performance for each epoch of the CNN.
```{r history performance}
plot(history)
```


```{no usar}
  # history <- model %>% fit(
  #   train_generator,
  #   steps_per_epoch = 64, #100
  #   epochs = 20, # 20
  #   validation_data = validation_generator,
  #   validation_steps = 50 #50
)
```

In order to save the model
```{r save_model_hdf5}
model %>% save_model_hdf5("cnn.h5")
```

In order to load the model
```{r load_model_hdf5}
model <- load_model_hdf5("cnn.h5")
```


## Tunning hyperparameter
In this section we going to tune the hyperparameter `batch_size` exploring the
grid c.16; 32; 64.

First of all, we set hyperparameter flags.
```{r flags}
FLAGS <- flags(
  flag_string("hl1", "batch size"))
```

Re-define the model introducing the flags in order to tune the hyperparameter.
```{r Tunning hyperparameter}
model %>% fit(train_generator, validation_generator, epochs = 10, 
              batch_size = FLAGS$hl1)
```

Training the model that is stored in `cnn_assignment.R` with the different `batch size` in a loop.
```{r}
for (hl1 in c(16, 32, 64)){
training_run("cnn_assignment.R", flags = c(hl1 = hl1))
}  
```

If we want see the performance of the runs that we did before:
```{r view runs}
View(ls_runs())
```

In order to compare the models:
```{r compare}
compare_runs(ls_runs())
```

### `callbacks()` Implemention

In this section is implemented a an early-stopping `callbacks()` that stop the training validation accuracy stops improving for more than two epochs.

```{r}
model %>% fit(train_generator, validation_generator, epochs = 10,
              callbacks = list(callback_model_checkpoint("cnn.h5", save_freq = 2),
                               callback_reduce_lr_on_plateau(monitor = "accuracy", factor = 0.1)),
              batch_size = 64)
```


## Performance of the CNN 

### Evaluate
```{r evaluate}
# evaluate
scores <- model %>% evaluate(validation_generator, 
                             validation_generator$labels, 
                             verbose = 0)

# Output metrics
cat('Test loss:', scores[[1]], '\n')
```

### Prediction

```{r prediction}
y_pred <-model %>% predict_classes(validation_generator)
```

### Confusion Matrix

```{r confusion Matrix}
confusionMatrix(as.factor(validation_generator$labels), as.factor(y_pred))
```




# Convolutional AutoEncoder (CAE)

6. Implement two Convolutional AutoEncoder (CAE). The first with 3 nodes
in z layer (or bottleneck), the second with 10 nodes in z layer. Feel free to
choose the number of convolutional layers, filter sizes, number of filters, 


## 1st Convolutional AutoEncoder

In this section we going to implement a CAE with 3 nodes in z layer.
- Convolutional layers
- Filter sizes
- Number of filters




## 2nd Convolutional AutoEncoder

In this section we going to implement a CAE with 10 nodes in z layer.
- Convolutional layers
- Filter sizes
- Number of filters



7. Represent graphically the results from images test to show the association
between z layer activations and the class images. Compare the representations
displayed by both CAE architectures.










